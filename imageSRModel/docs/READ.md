# 模型推理的整个过程： 

## 0、准备工作模型初始化设置
* 创建TensorRT 推理对象
* 设置输入数据的形状
* 申请和设置计算过程中的临时地址
## 1、输入数据的操作
* 分配GPU内存
* 设置输入和输出数据地址
* 推理前的数据格式转换

## 2、模型推理操作
* 模型推理计算

## 3、模型推理结果的返回处理
* 推理之后的数据格式转换从而保证和输入的格式相同

## 4、下一次的数据帧准备
* 释放上一帧的gpu，并且同时准备下一帧的数据


# 接口调用操作：
！！！ 数据格式转换：过程优化，从而减少单帧数据转换的时间

1、模型初始化：
* engine： 文件的路径信息
* 处理图像的长和宽 通道为3通道的rgb或者BGR
* 倍数： 当前模型只支持x2超分操作


!!! 模型输入的数据格式是0 -255的float0-1类型的数据操作

2、模型数据准备
* 输入的数据格式：
由于BGR图像的data一维数组是unchar类型，并且排列的方式是BGRBGRBGR 
需要通过核函数(减少数据前处理的时间)转换为：
    * float类型0-1 
    * 排列方式为BBBBBBBGGGGGGRRRRRR(即先存储B通道信息，再存储G通道信息和R通道信息) 
    (第二步可以我这里做，但是第一步需要进行转换)


3、模型推理
* 提供转换之后的输入数据的GPU地址
* 模型推理: 推理的结果仍旧是BBBBBBBBGGGGGGGRRRRRRRR float 0-1范围
* 推理结果的转换
* 返回处理之后的数据GPU地址


4、下一帧数据同样的操作


···

5、Ending: 初始化信息的销毁

